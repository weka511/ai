% This document collects my derivations of equations relevant to Active Inference

% Copyright (c) 2022-2024 Simon Crase

% This script is free software: you can redistribute it and/or modify
% it under the terms of the GNU General Public License as published by
% the Free Software Foundation, either version 3 of the License, or
% (at your option) any later version.

% This script is distributed in the hope that it will be useful,
% but WITHOUT ANY WARRANTY; without even the implied warranty of
% MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
% GNU General Public License for more details.

% You should have received a copy of the GNU General Public License
% along with this script.  If not, see <https://www.gnu.org/licenses/>.


\documentclass[]{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage[toc,page]{appendix}
\usepackage{cancel}
\usepackage{caption}
\usepackage{chronology}
\usepackage{float}
\usepackage[toc,nonumberlist]{glossaries}
\usepackage{glossaries-extra}
\usepackage{graphicx}
\usepackage{mathrsfs}
\usepackage{mathtools}
\usepackage{subcaption}
\usepackage{thmtools}
\usepackage{tocloft}
\usepackage{url}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}
\newcommand{\stcomp}[1]{\widetilde{#1}}
\newtheorem{defn}{Definition}
\newtheorem{thm}{Theorem}
\newtheorem{lemma}[thm]{Lemma}
\graphicspath{{figs/}}
\widowpenalty10000
\clubpenalty10000

\makeglossaries
%opening
\title{Active inference}
\author{Simon Crase}

\begin{document}
	
\newglossaryentry{gls:sde}{
	name={stochastic differential equation},
	description={
	A stochastic differential equation is a differential equation whose coefficients are random numbers or random functions of the independent variable (or variables)}}

\newglossaryentry{gls:helmholz}{
	name={Helmholtz Decomposition},
	description={The Helmholtz Decomposition Theorem, or the fundamental theorem of vector calculus, states that any well-behaved vector field can be decomposed into the sum of a longitudinal (diverging, non-curling, irrotational) vector field and a transverse (solenoidal, curling, rotational, non-diverging) vector field\cite{baird2012helmholtz}}}
\maketitle

\begin{abstract}
This document collects my derivations of equations from Karl Fristons's work, specifically \cite{friston_free_2006,friston_free-energy_2009,friston_life_2013,friston2016therefore,friston_interesting_2021,friston2022free}. It is intended to help me understand the details of the Free Energy Principle.
\end{abstract}

\tableofcontents
\listoftheorems

\section{Introduction}

\begin{figure}[H]
	\caption{Timeline for Active Inference references}
	\begin{chronology}[5]{2002}{2024}{18cm}[\textwidth]
		\event{2003}{\cite{beal2003variational}Variational algorithms for approximate Bayesian inference}
		\event{2006}{\color{blue}\cite{friston_free_2006}A Free Energy Principle for the brain}
		\event{2009}{\color{blue}\cite{friston_free-energy_2009}The free-energy principle: a rough guide to the brain}
		\event{2013}{\color{blue}\cite{friston_life_2013}Life as we Know it}
		\event{2016}{\color{blue}\cite{friston2016therefore}I am therefore I think}
		\event{2017}{\cite{Blei2017}Variational inference: A review for statisticians}
		\event{2021}{\color{blue}\cite{friston_interesting_2021}Some Interesting Observations on the Free Energy Principle}
		\event{\decimaldate{1}{1}{2022}}{\color{blue}\cite{friston2022free}The free energy principle made simpler but not too simple}
		\event{\decimaldate{30}{10}{2022}}{\color{blue}\cite{Parr2022Active}Active Inference: The Free Energy Principle in Mind, Brain and Behavior}
	\end{chronology}
\end{figure}

\begin{table}[H]
	\begin{center}
		\caption{Notation for Active Inference references}
		\begin{tabular}{|l|c|c|c|c|c|}\hline
			&\cite{beal2003variational}&\cite{friston_life_2013}&\cite{friston2016therefore}&\cite{Blei2017}&\cite{friston2022free,Parr2022Active}\\ \hline
			External State&x&$\Psi$&$\Psi$&z&$\eta$\\ \hline
			Internal State&&$\lambda$&r&&$\mu$\\ \hline
			Sensory State&y&s&s&x&s\\ \hline
			Action State&&a&a&&a\\ \hline
			Autonomous States&&&&& $\alpha(a,\mu)$\\\hline
			Blanket States&&&&&$b(s,a)$\\ \hline
			Particular States&&&&&$\pi(b,\mu)$\\ \hline
			Ergodic Density&p&$p(\psi,s,a,\lambda\vert m)$&$p(\psi,s,a,r\vert m)$&p&p\\ \hline
			Recognition Density or Variational Density&q&$q(\psi\vert \mu)$&$q(\psi\vert \mu)$&q&q\\ \hline
		\end{tabular}
	\end{center}
\end{table}

\section{Fokker-Planck Equation}

\begin{thm}[Fokker-Planck equation]
	If $\vec{x}$ satisfies the \gls{gls:sde}
	\begin{align*}
		\dot{\vec{x}} =& f(\vec{x}) + \omega \numberthis \label{eq:dynamics}
	\end{align*}
	then the probability distribution over states is given by:
	\begin{align*}
		\dot{p}(\vec{x}\vert m) =& \nabla \cdot \Gamma \nabla p -\nabla \cdot(f p) \numberthis \label{eq:fokker:planck}
	\end{align*}
	See \cite[(2.2)]{friston_life_2013} and  \cite[Chapter 33]{cvitanovic2005chaos}.
\end{thm}

\begin{proof}
	\cite[Section 33.3]{cvitanovic2005chaos}
\end{proof}

\cite{friston_life_2013,friston2012free}

\begin{thm}[Equilibrium distribution for Fokker-Planck]
	The equilibrium distribution for \eqref{eq:fokker:planck} is given by:
	\begin{align*}
		p(\vec{x}\vert m) =& \exp \big(-G(\vec{x})\big) \text{, where $G$ satisfies}\\
		f =& -(\Gamma + R) \cdot \nabla G \text{, where} \numberthis \label{eq:f:Gamma:R}\\
		\nabla.R =& 0 \text{ and R antisymmetric}
	\end{align*}
	
\end{thm}
\begin{proof}
The equilibrium distribution of \eqref{eq:fokker:planck} satisfies:
	\begin{align*}
		\dot{p}(\vec{x}\vert m) =&0 \text{, i.e.}\\
		\nabla \cdot (\Gamma \nabla p -f p)=&0 \numberthis \label{eq:fokker:plank:eq}
	\end{align*}
	Since $	p(\vec{x}\vert m) > 0$, we can define:
	\begin{align*}
		G(x) =& - \ln{}p(\vec{x}\vert m) \text{, so}\\
		p(\vec{x}\vert m) =& \exp \big(-G(\vec{x})\big) \text{. Then}\\
		\nabla p =& - \exp \big(-G(\vec{x})\big) \nabla G(\vec{x}) \numberthis \label{eq:grad:p}\\
		=& - p \nabla G(\vec{x})
	\end{align*}
	 whence \eqref{eq:fokker:plank:eq} becomes
	\begin{align*}
		-\nabla \cdot [(\Gamma \nabla G +f)p]=&0\\
		(\Gamma \nabla G +f)p =& \nabla \times \vec{A} \text{, for some $\vec{A}$}\\
		=& -p \vec{R} \cdot \nabla G \text{, for some $R$, whence}\\
		f =& -(\Gamma + R) \cdot \nabla G \text{, the \gls{gls:helmholz}-- \cite[(2.3)]{friston_life_2013}}
	\end{align*}
\end{proof}
\begin{proof}[Alternative proof using indices.]
	Equation \eqref{eq:f:Gamma:R} expands as 
	\begin{align*}
		f_i =& - \sum_{j}\big(\Gamma_{ij}+R_{ij}\big)\partial_j G \text{, whence}\\
		\big(\Gamma\nabla p - \vec{f} p\big)_i =& \sum_{j}\big[\Gamma_{ij}\partial_j p\big] -  f_i p\\
		=& \sum_{j}\big[\Gamma_{ij}\partial_j p\big] + p\sum_{j}\big(\Gamma_{ij}+R_{ij}\big)\partial_j G  \\
		=& - \cancel{\sum_{j}\big[\Gamma_{ij}p\partial_j G\big]} + p\sum_{j}\big(\cancel{\Gamma_{ij}}+R_{ij}\big)\partial_j G \\
		=& p\sum_{j}R_{ij}\partial_j G
	\end{align*}
	Calculating the divergence:
	\begin{align*}
		\nabla \cdot \big(\Gamma\nabla p - \vec{f} p\big) =& \sum_{i,j} \partial_i \big[p R_{ij}\partial_j G\big]\\
		=& \sum_{i,j} \big[(\partial_i p) R_{ij}\partial_j G + p (\partial_i  R_{ij})\partial_j G +\underbrace{ p R_{ij}(\partial_i \partial_j G)}_{=0}\big]\\
		=& \sum_{i,j} \big[-\underbrace{p (\partial_i G) R_{ij}\partial_j G}_{=0} + p (\partial_i  R_{ij})\partial_j G \big] \\
		=& p \sum_{i,j} \underbrace{(\partial_i  R_{ij})}_{\nabla\cdot R=0}\partial_j G\\
		=& 0
	\end{align*}

\end{proof}

\section{Free Energy}


From \cite{friston2016therefore}
\begin{align*}
	F(s,a,r) =& E_q\big[L(x)\big]-H\big[q(\Psi\vert r)\big] \text{, where}\\
	L(x) =& -\ln{p(\psi,s,a,r)}\\
	F(s,a,r) =&  E_q\big[ -\ln{p(\psi,s,a,r)} - \ln{q(\Psi\vert r)}\big]
\end{align*}

From \cite{friston2022free}

\begin{align*}
	F\big(\pi(\tau)\big) =& E_q\big[\ln q\big(\eta(\tau)\big) - \ln p\big(\eta(\tau)\big) - \ln p\big(\pi(\tau)\vert\eta(\tau)\big)\big] \numberthis \label{eq:free:energy}
\end{align*}

We can rearrange \eqref{eq:free:energy} in several different ways.
\begin{align*}
	F\big(\pi(\tau)\big) =& E_q\big[\ln q\big(\eta(\tau)\big) - \ln p\big(\eta(\tau)\big) - \ln p\big(\pi(\tau)\vert\eta(\tau)\big)\big]\\
	=& E_q\big[\ln q\big(\eta(\tau)\big)\big] - E_q \bigg[\ln \big[p\big(\eta(\tau)\big)  p\big(\pi(\tau)\vert\eta(\tau)\big)\big]\bigg]\\
	=& E_q\big[\ln q\big(\eta(\tau)\big)\big] - E_q \bigg[\ln \big[  p\big(\pi(\tau),\eta(\tau)\big)\big]\bigg]\\
	=&-\underbrace{H(q\big(\eta(\tau)\big))}_\text{Entropy}  \underbrace{- E_q \bigg[\ln \big[  p\big(\pi(\tau),\eta(\tau)\big)\big]\bigg]}_\text{Identified with Expected Energy in \cite{friston2022free}}
\end{align*}
This agrees with the thermodynamic definition of Helmholtz Free Energy $U-TS$, where $U$ is the enthalpy and $S$ the entropy, if we set the temperature $T=1$.
\begin{align*}
	F\big(\pi(\tau)\big) =& E_q\big[\ln q\big(\eta(\tau)\big) - \ln p\big(\eta(\tau)\big) - \ln p\big(\pi(\tau)\vert\eta(\tau)\big)\big]\\
	=& E_q\big[\ln \frac{q\big(\eta(\tau)\big)}{p\big(\eta(\tau)\big)}   \big] - E_q \bigg[\ln \big[  p\big(\pi(\tau)\vert\eta(\tau)\big)\big]\bigg]\\
	=& D_{KL}\big(q\big(\eta(\tau)\big)\vert\vert p\big(\eta(\tau)\big)\big)- E_q \bigg[\ln \big[  p\big(\pi(\tau)\vert\eta(\tau)\big)\big]\bigg]\\
	\ge&- E_q \bigg[\ln \big[  p\big(\pi(\tau)\vert\eta(\tau)\big)\big]\bigg]
\end{align*}

\begin{align*}
	F\big(\pi(\tau)\big) =& E_q\big[\ln q\big(\eta(\tau)\big) - \ln p\big(\eta(\tau)\big) - \ln p\big(\pi(\tau)\vert\eta(\tau)\big)\big]\\
	=& E_q\big[\ln q\big(\eta(\tau)\big)  - \ln p\big(\pi(\tau)\vert\eta(\tau)\big)\big] +  E_q\big[- \ln p\big(\eta(\tau)\big)\big]\\
	=& D_{KL}\big(q\big(\eta(\tau)\big)\vert\vert p\big(\pi(\tau)\vert\eta(\tau)\big)\big)+  E_q\big[- \ln p\big(\eta(\tau)\big)\big]
\end{align*}

\begin{appendices}
	\section{Boolean Algebra}
	We define the symmetric difference of two sets:
	\begin{align*}
		A \triangle B \coloneqq& \big(A \setminus B\big) \bigcup \big(B \setminus  A\big)\\
		=& \big(A \cap \stcomp{B}\big) \bigcup \big(B \cap \stcomp{A}\big) \numberthis \label{eq:synn:diff_regular:diff}\\
	\end{align*}
	We also have two useful distributive laws.
	\begin{align*}
		A \bigcup \big(B \cap C \big) =& \big(A \cup B\big) \bigcap  \big(A \cup C\big) \numberthis \label{eq:dist:cup:cap}\\
		A \bigcap \big(B \cup C \big) =& \big(A \cap B\big) \bigcup  \big(A \cap C\big)	\numberthis \label{eq:dist:cap:cup}	
	\end{align*}
	Applying \eqref{eq:dist:cup:cap} to \eqref{eq:synn:diff_regular:diff}:
	\begin{align*}
		A \triangle B =&\big[\big(A \cap \stcomp{B}\big) \cup B\big] \bigcap \big[ \big(A \cap \stcomp{B}\big) \cup \stcomp A \big] \numberthis \label{eq:symm:diff:expanded}
	\end{align*}
	Splitting the two terms in \eqref{eq:symm:diff:expanded}, applying \eqref{eq:dist:cup:cap}, and canceling intersections with the universal set:
	\begin{align*}
		\big[\big(A \cap \stcomp{B}\big) \cup B\big] =& \big(A \cup B\big) \cancel{\bigcap \big(B \cup \stcomp{B}}\big)\\
		\big[ \big(A \cap \stcomp{B}\big) \cup \stcomp A \big] =& \cancel{\big(A\cup\stcomp{A} \big) \bigcap} \big(\stcomp{B} \cup\stcomp{A}\big) \text{, so \eqref{eq:symm:diff:expanded} becomes}\\
		A \triangle B =& \big(A \cap B\big) \bigcup \big(\stcomp{B} \cup\stcomp{A}\big) \numberthis \label{eq:symm:diff:without:diff}
	\end{align*}

	\begin{lemma}
		\begin{align*}
			\forall& A,B,C\\
			A \triangle B =& \big(A\triangle C\big) \triangle \big(B\triangle C\big)\\
		    \subseteq& \big(A\triangle C\big) \bigcup \big(B\triangle C\big)
		\end{align*}
	\end{lemma}
	\begin{proof}
		content...
	\end{proof}
\end{appendices}

\printglossaries

% bibliography goes here

\bibliographystyle{unsrt}
\addcontentsline{toc}{section}{Bibliography}
\bibliography{ActiveInference}

\end{document}
